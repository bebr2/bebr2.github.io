<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>Kaggle首战记录(2)-English Language Learning-baseline的数据处理</title>
    <link href="/2022/09/11/Kaggle%E9%A6%96%E6%88%98%E8%AE%B0%E5%BD%95(2)-English%20Language%20Learning-baseline%E7%9A%84%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86/"/>
    <url>/2022/09/11/Kaggle%E9%A6%96%E6%88%98%E8%AE%B0%E5%BD%95(2)-English%20Language%20Learning-baseline%E7%9A%84%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86/</url>
    
    <content type="html"><![CDATA[<p>这部分是和baseline有关的数据处理环节。</p><span id="more"></span><h2 id="EDA"><a href="#EDA" class="headerlink" title="EDA"></a>EDA</h2><p>和统计一样，上来得先做一个数据探索EDA。</p><p><img src="/img/article_content/2022-09-11/0.png"></p><p>瞄一下数据，大概是成正态分布，这比较符合常识，因此可以说不太存在数据不平衡的现象。</p><p>注意这里的数据不平衡是指训练集和真实分布的差距，而不是score值的相互比较。</p><p>数据共3911行，说实话不多，因此也比较依赖之后的数据增强。</p><p>baseline打算用roberta-base做预训练层，roberta的预训练任务token数都是不超过512的，因此EDA也要关注数据过roberta的tokenizer后的情况。</p><p>导入数据：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python">path = <span class="hljs-string">&#x27;../../../mydata/ka/ell/train.csv&#x27;</span><br><br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br>data = pd.read_csv(path)<br>data[<span class="hljs-string">&#x27;full_text&#x27;</span>] = data[<span class="hljs-string">&#x27;full_text&#x27;</span>].apply(<span class="hljs-keyword">lambda</span> x: x.strip()) <span class="hljs-comment">#简单地去除一下头尾</span><br><br><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> RobertaTokenizer<br>tokenizer = RobertaTokenizer.from_pretrained(<span class="hljs-string">&#x27;../../../mydata/roberta-base/&#x27;</span>)<br></code></pre></td></tr></table></figure><h3 id="token数"><a href="#token数" class="headerlink" title="token数"></a>token数</h3><p>然后把文本列用tokenizer映射一下，关注token数。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python">token_len_df = data[<span class="hljs-string">&#x27;full_text&#x27;</span>].<span class="hljs-built_in">map</span>(<span class="hljs-keyword">lambda</span> x : tokenizer(x, return_tensors=<span class="hljs-string">&#x27;pt&#x27;</span>)[<span class="hljs-string">&quot;input_ids&quot;</span>].shape[<span class="hljs-number">1</span>])<br><br><span class="hljs-built_in">print</span>(token_len_df.<span class="hljs-built_in">max</span>())<br><span class="hljs-built_in">print</span>(token_len_df.<span class="hljs-built_in">min</span>())<br><span class="hljs-built_in">print</span>(token_len_df.mean())<br><span class="hljs-built_in">print</span>(token_len_df.median())<br><span class="hljs-built_in">print</span>(token_len_df.count())<br><span class="hljs-built_in">print</span>(token_len_df[token_len_df &gt; <span class="hljs-number">512</span>].count())<br></code></pre></td></tr></table></figure><p>结果如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-number">1457</span><br><span class="hljs-number">28</span><br><span class="hljs-number">493.9312196369215</span><br><span class="hljs-number">463.0</span><br><span class="hljs-number">3911</span><br><span class="hljs-number">1555</span><br></code></pre></td></tr></table></figure><p>可以看到最长的已经到1457了，而且大于512的有接近一半了，因此考虑切割。</p><h3 id="段落数"><a href="#段落数" class="headerlink" title="段落数"></a>段落数</h3><p>切割怎么切好呢？段落一般是文意的分割点，因此我们再EDA一下段落：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_paragraph_count</span>(<span class="hljs-params">x</span>): <span class="hljs-comment">#计算段落数量，其实后来想想直接用正则表达式对文本操作不是更方便（</span><br>    sen_tensor = tokenizer(x, return_tensors=<span class="hljs-string">&#x27;pt&#x27;</span>)[<span class="hljs-string">&quot;input_ids&quot;</span>][<span class="hljs-number">0</span>]<br>    count = <span class="hljs-number">0</span><br>    <span class="hljs-keyword">for</span> token <span class="hljs-keyword">in</span> sen_tensor:<br>        <span class="hljs-keyword">if</span> token.item() == <span class="hljs-number">50118</span>:<br>            count += <span class="hljs-number">1</span><br>    <span class="hljs-keyword">return</span> count / <span class="hljs-number">2</span> + <span class="hljs-number">1</span><br><br>paragraph_count_df = data[<span class="hljs-string">&#x27;full_text&#x27;</span>].<span class="hljs-built_in">map</span>(get_paragraph_count)<br><br><span class="hljs-built_in">print</span>(paragraph_count_df.<span class="hljs-built_in">max</span>())<br><span class="hljs-built_in">print</span>(paragraph_count_df.<span class="hljs-built_in">min</span>())<br><span class="hljs-built_in">print</span>(paragraph_count_df.mean())<br><span class="hljs-built_in">print</span>(paragraph_count_df.median())<br><span class="hljs-built_in">print</span>(paragraph_count_df[paragraph_count_df &gt; <span class="hljs-number">30</span>].count())<br></code></pre></td></tr></table></figure><p>结果如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-number">52.0</span><br><span class="hljs-number">1.0</span><br><span class="hljs-number">5.538097673229353</span><br><span class="hljs-number">5.0</span><br><span class="hljs-number">5</span><br></code></pre></td></tr></table></figure><p>也就是有的居然达到了52段！实在是丧心病狂，看一下原文：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-built_in">print</span>(data[<span class="hljs-string">&#x27;full_text&#x27;</span>][paragraph_count_df.idxmax()])<br></code></pre></td></tr></table></figure><p>输出如下，只能说很会玩：</p><p><img src="/img/article_content/2022-09-11/1.png"></p><p>本来我还进行了段落中最大token数的探索，但现在感觉没必要，无论探索结果如何，你都不可能仅仅把段落数作为唯一切割依据。</p><h2 id="数据处理"><a href="#数据处理" class="headerlink" title="数据处理"></a>数据处理</h2><p>数据处理的方法就呼之欲出了，对于一条长文本，先转化为token，然后不断二分切割，当然这个二分只是“类”二分，最好按段落切割，其次的分割标准是句号。然后我发现有的作文连句号都没有，因此还加上了逗号和空格。</p><h3 id="处理过程"><a href="#处理过程" class="headerlink" title="处理过程"></a>处理过程</h3><p>代码如下：</p><p>是用递归实现的。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">txt_to_tensor</span>(<span class="hljs-params">x</span>):<br>    x = x.strip()<br>    sen_tensor = tokenizer(x, return_tensors=<span class="hljs-string">&#x27;pt&#x27;</span>, padding=<span class="hljs-string">&quot;max_length&quot;</span>, max_length=<span class="hljs-number">512</span>)[<span class="hljs-string">&quot;input_ids&quot;</span>] <span class="hljs-comment">#padding补齐，不然没办法cat</span><br>    <span class="hljs-keyword">if</span> sen_tensor.shape[<span class="hljs-number">1</span>] &lt;= <span class="hljs-number">512</span>:  <span class="hljs-comment">#如果本段落合格了，则返回</span><br>        <span class="hljs-keyword">return</span> sen_tensor<br>    str_len_mid = <span class="hljs-built_in">len</span>(x) // <span class="hljs-number">2</span> <span class="hljs-comment">#句子中央</span><br>    about_mid = <span class="hljs-number">0</span><br>    <span class="hljs-keyword">try</span>:<br>        about_mid = str_len_mid + x[str_len_mid:].index(<span class="hljs-string">&#x27;\n&#x27;</span>) <span class="hljs-comment">#否则尝试在句子中央之后找一找换行符</span><br>    <span class="hljs-keyword">except</span>:<br>        <span class="hljs-keyword">try</span>:<br>            about_mid = str_len_mid - x[str_len_mid::-<span class="hljs-number">1</span>].index(<span class="hljs-string">&#x27;\n&#x27;</span>) <span class="hljs-comment">#如果找不到，在句子中央之前找一找换行符</span><br>        <span class="hljs-keyword">except</span>:<br>            <span class="hljs-keyword">try</span>:<br>                about_mid = str_len_mid + x[str_len_mid:].index(<span class="hljs-string">&#x27;.&#x27;</span>) <span class="hljs-comment">#再找不到，找找句号</span><br>                x1 = txt_to_tensor(x[:about_mid])<br>                x2 = txt_to_tensor(x[about_mid+<span class="hljs-number">1</span>:])<br>                <span class="hljs-keyword">return</span> torch.cat((x1, x2))<br>            <span class="hljs-keyword">except</span>:<br>                about_mid = str_len_mid + x[str_len_mid:].index(<span class="hljs-string">&#x27;,&#x27;</span>) <span class="hljs-comment">#逗号</span><br>                x1 = txt_to_tensor(x[:about_mid])<br>                x2 = txt_to_tensor(x[about_mid+<span class="hljs-number">1</span>:])<br>                <span class="hljs-keyword">return</span> torch.cat((x1, x2))<br>    <span class="hljs-keyword">if</span> about_mid &gt; str_len_mid * <span class="hljs-number">1.5</span> <span class="hljs-keyword">or</span> about_mid &lt; str_len_mid * <span class="hljs-number">0.5</span>: <span class="hljs-comment">#尽量分割合理，如果两边长度差别太大，试试用句号分割</span><br>        <span class="hljs-keyword">try</span>:<br>            about_mid2 = str_len_mid + x[str_len_mid:].index(<span class="hljs-string">&#x27;.&#x27;</span>)<br>            <span class="hljs-keyword">if</span> <span class="hljs-built_in">abs</span>(about_mid2 - str_len_mid) &lt; <span class="hljs-built_in">abs</span>(about_mid - str_len_mid):<br>                about_mid = about_mid2<br>        <span class="hljs-keyword">except</span>:<br>            <span class="hljs-keyword">pass</span><br>    x1 = txt_to_tensor(x[:about_mid]) <span class="hljs-comment">#再递归探索</span><br>    x2 = txt_to_tensor(x[about_mid+<span class="hljs-number">1</span>:])<br>    <span class="hljs-keyword">return</span> torch.cat((x1, x2))<br></code></pre></td></tr></table></figure><p>这个处理方法是<strong>有问题的</strong>：</p><p>首先，分割其实可以不用那么合理，毕竟连28个token的文章都有。</p><p>其次，对于不同的评分维度，数据处理的要求是不同的，本方法的目的是尽可能地保存“段落”、“章节”，而像语法句法、短语词汇这些可能根本不需要保留这些信息，但在baseline六个维度一起训练的条件下这还是有必要的。</p><p>处理方法的问题也给数据增强带来思路（虽然这不叫增强了叫查漏补缺）</p><p>不管那么多了，我们apply一下，再看看我们处理后每个数据的子句多少：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python">data[<span class="hljs-string">&#x27;full_tensor&#x27;</span>] = data[<span class="hljs-string">&#x27;full_text&#x27;</span>].apply(txt_to_tensor)<br><br>d = data[<span class="hljs-string">&#x27;full_tensor&#x27;</span>].<span class="hljs-built_in">map</span>(<span class="hljs-keyword">lambda</span> x: x.shape[<span class="hljs-number">0</span>])<br><span class="hljs-built_in">print</span>(d.<span class="hljs-built_in">max</span>())<br><span class="hljs-built_in">print</span>(d[d&gt;<span class="hljs-number">1</span>].count())<br></code></pre></td></tr></table></figure><p>输出如下：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-number">5</span><br><span class="hljs-number">1555</span><br></code></pre></td></tr></table></figure><p>也就是最多有5个子句，多于1个子句的有1555个，和上面大于512token的数量一样。</p><h3 id="数据集创建"><a href="#数据集创建" class="headerlink" title="数据集创建"></a>数据集创建</h3><p>写一个十折交叉检验的数据集：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">writing_dataset</span>(<span class="hljs-title class_ inherited__">Dataset</span>):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, data=data, ki = <span class="hljs-number">0</span>, typ=<span class="hljs-string">&#x27;train&#x27;</span></span>):<br>        self.x = []<br>        self.y = [] <span class="hljs-comment">#六维的评分</span><br>        self.k = <span class="hljs-number">10</span> <span class="hljs-comment">#10折交叉</span><br>        self.xy = []<br>        <span class="hljs-keyword">for</span> dat <span class="hljs-keyword">in</span> data.iterrows():<br>            self.x.append(dat[<span class="hljs-number">1</span>][<span class="hljs-string">&#x27;full_tensor&#x27;</span>])<br>            self.y.append(torch.tensor([dat[<span class="hljs-number">1</span>][<span class="hljs-string">&#x27;cohesion&#x27;</span>], dat[<span class="hljs-number">1</span>][<span class="hljs-string">&#x27;syntax&#x27;</span>], dat[<span class="hljs-number">1</span>][<span class="hljs-string">&#x27;vocabulary&#x27;</span>], dat[<span class="hljs-number">1</span>][<span class="hljs-string">&#x27;phraseology&#x27;</span>], dat[<span class="hljs-number">1</span>][<span class="hljs-string">&#x27;grammar&#x27;</span>], dat[<span class="hljs-number">1</span>][<span class="hljs-string">&#x27;conventions&#x27;</span>]]))<br>        self.length = <span class="hljs-built_in">len</span>(self.y)<br>        self.xy.extend((self.x[i], self.y[i]) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(self.length))<br>        random.seed(<span class="hljs-number">1</span>)<br>        random.shuffle(self.xy)<br>        self.my_xy = []<br>        every_z_len = self.length // self.k<br>        <span class="hljs-keyword">if</span> typ == <span class="hljs-string">&#x27;val&#x27;</span>:<br>            self.my_xy = self.xy[every_z_len * ki : every_z_len * (ki+<span class="hljs-number">1</span>)]<br>        <span class="hljs-keyword">elif</span> typ == <span class="hljs-string">&#x27;train&#x27;</span>:<br>            self.my_xy = self.xy[: every_z_len * ki] + self.xy[every_z_len * (ki+<span class="hljs-number">1</span>) :]<br>        <span class="hljs-keyword">else</span>:<br>            <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;Wrong type!&#x27;</span>)<br><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__getitem__</span>(<span class="hljs-params">self, index</span>):<br>        <span class="hljs-keyword">return</span> self.my_xy[index]<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__len__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-keyword">return</span> <span class="hljs-built_in">len</span>(self.my_xy)<br></code></pre></td></tr></table></figure><p>平平无奇的写法，注意数据集的自变量是二维的tensor，tensor的第一个维度（子句数）是不一样的，所以在dataloader的时候要写一个collate函数处理一下。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">collate</span>(<span class="hljs-params">batches</span>):<br>    max_sub_count = <span class="hljs-number">0</span><br>    first = <span class="hljs-literal">True</span><br>    x = <span class="hljs-literal">None</span><br>    y = <span class="hljs-literal">None</span><br>    <span class="hljs-keyword">for</span> batch <span class="hljs-keyword">in</span> batches:<br>        max_sub_count = <span class="hljs-built_in">max</span>(max_sub_count, batch[<span class="hljs-number">0</span>].shape[<span class="hljs-number">0</span>]) <span class="hljs-comment">#统计batch内的最大子句数</span><br>    <span class="hljs-keyword">for</span> batch <span class="hljs-keyword">in</span> batches:<br>        <span class="hljs-keyword">if</span> first:<br>            first = <span class="hljs-literal">False</span><br>            x = batch[<span class="hljs-number">0</span>]<br>            y = batch[<span class="hljs-number">1</span>].unsqueeze(<span class="hljs-number">0</span>) <span class="hljs-comment">#batch[1]的维度是[6]，这里变成了[1, 6]才好cat</span><br>        <span class="hljs-keyword">else</span>:<br>            x = torch.cat((x, batch[<span class="hljs-number">0</span>]))<br>            y = torch.cat((y, batch[<span class="hljs-number">1</span>].unsqueeze(<span class="hljs-number">0</span>)))<br><br>        need_sub_count = max_sub_count - batch[<span class="hljs-number">0</span>].shape[<span class="hljs-number">0</span>]<br><br>        <span class="hljs-keyword">if</span> need_sub_count:<br>            x = torch.cat((x, torch.repeat_interleave(batch[<span class="hljs-number">0</span>][<span class="hljs-number">0</span>].unsqueeze(<span class="hljs-number">0</span>), need_sub_count, dim=<span class="hljs-number">0</span>))) <span class="hljs-comment">#没到最大子句的，取第一个子句来补充，注意，这导致了我们池化层必须是maxpool，或者反过来maxpool下我们才能这么做。</span><br><br>    <span class="hljs-keyword">return</span> x, y<br></code></pre></td></tr></table></figure><p>数据处理就到这里。</p>]]></content>
    
    
    <categories>
      
      <category>Kaggle实战</category>
      
      <category>English Language Learning</category>
      
    </categories>
    
    
    <tags>
      
      <tag>NLP</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Kaggle首战记录(1)-English Language Learning-比赛简介及读题</title>
    <link href="/2022/09/10/Kaggle%E9%A6%96%E6%88%98%E8%AE%B0%E5%BD%95(1)-English%20Language%20Learning-%E6%AF%94%E8%B5%9B%E7%AE%80%E4%BB%8B%E5%8F%8A%E8%AF%BB%E9%A2%98/"/>
    <url>/2022/09/10/Kaggle%E9%A6%96%E6%88%98%E8%AE%B0%E5%BD%95(1)-English%20Language%20Learning-%E6%AF%94%E8%B5%9B%E7%AE%80%E4%BB%8B%E5%8F%8A%E8%AF%BB%E9%A2%98/</url>
    
    <content type="html"><![CDATA[<p>第一次参加kaggle的比赛，选择了这个比赛，现在距正式做已经一周时间了，发现做这个能让自己注意很多深度学习的细节（例如显存等平时上课看论文不太关心的），而且自己能在反思中收获很多东西。刚好一周 41hours 的GPU配额快用完了。因此决定把自己的比赛过程记录下来。</p><span id="more"></span><h2 id="比赛简介"><a href="#比赛简介" class="headerlink" title="比赛简介"></a>比赛简介</h2><h3 id="时间"><a href="#时间" class="headerlink" title="时间"></a>时间</h3><p><img src="/img/article_content/2022-09-10/3.png"></p><h3 id="内容"><a href="#内容" class="headerlink" title="内容"></a>内容</h3><p>训练一个模型，评估 8-12 年级英语语言学习者 (ELL) 的语言能力，输入是每个学生的写作文本（长文本），输出是六个维度的评分，评分范围为1-5分，评分是离散的，0.5分为一个间隔。</p><p>需要评分的六个维度分别为：<span class="label label-primary">cohesion</span>  <span class="label label-primary">syntax</span> <span class="label label-primary">vocabulary</span> <span class="label label-primary">phraseology</span> <span class="label label-primary">grammar</span> <span class="label label-primary">conventions</span>。中文的直译是：连贯性、句法、词汇、短语、惯例用法（有一说一这些已经对非英语母语者不友好了qaq）。</p><p>评估模型的好坏有两个赛道，一个是质量赛道，一个是效率赛道。</p><p>质量赛道的评估函数为类MSE函数，其中N_t就是6，n是总测试样本数：</p><p><img src="/img/article_content/2022-09-10/4.png"></p><p>效率赛道在此基础上考虑运行时间（只允许在CPU上运行），函数为：</p><p><img src="/img/article_content/2022-09-10/5.png"></p><p>其中Base是baseline的MCRMSE，minMCRMSE是榜上的最好MCRMSE。</p><h2 id="读题"><a href="#读题" class="headerlink" title="读题"></a>读题</h2><p>首次参加比赛还是有很多不懂的，这里只是抛砖引玉写自己的理解而已（毕竟现在在质量赛道还是排名很后的orz）。</p><p>首先，<strong>回归模型和分类模型</strong>是需要斟酌的，回归模型的好处是损失函数一般用MSE，和评估函数很接近；为什么考虑分类模型呢？这是因为评分是离散的，可以看成是分类，而且分类给人的感觉就比较容易达到高分。但是分类模型的损失函数——交叉熵及其变体，都不会考虑到<strong>分错的严重程度</strong>，比如1分的打成3分明显比打成5分好一点，我的初步思考是在生成标签的时候做一些手脚，比如标签平滑时对远处的标签赋为更小甚至负值（当然这样损失函数的计算要注意），但这样有没有理论依据，说实话我还是太菜了没想出来，所以采用了回归模型。</p><p>其次，这几个指标能不能一起训练？我的baseline（其实也是我目前的次优分数）就是直接在预训练模型后加两层linear——这导致了微调时预训练模型是同时要去适应六个维度的，细看六个维度，cohesion是<strong>paragraph-level</strong>的，syntax、grammar是<strong>sentence-level</strong>的，而vocabulary、conventions、phraseology虽然都是句子内部的，但侧重点又有所不同，所以同时训练结果必是比较差的。但是同时训练的好处是：它能在<strong>效率赛道</strong>上竞争！毕竟你让CPU跑一次大模型和跑两次大模型所用时间实在是天差地别。之后也会提到，在数据增强的时候，这几种的数据增强方向绝对是有不同的。</p><p>其他的后面想到再在后面的文章提了，或者在这里更新。</p>]]></content>
    
    
    <categories>
      
      <category>Kaggle实战</category>
      
      <category>English Language Learning</category>
      
    </categories>
    
    
    <tags>
      
      <tag>NLP</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>论文阅读笔记 （LS导致隐式长度惩罚）</title>
    <link href="/2022/08/24/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%20%EF%BC%88LS%E5%AF%BC%E8%87%B4%E9%9A%90%E5%BC%8F%E9%95%BF%E5%BA%A6%E6%83%A9%E7%BD%9A%EF%BC%89/"/>
    <url>/2022/08/24/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%20%EF%BC%88LS%E5%AF%BC%E8%87%B4%E9%9A%90%E5%BC%8F%E9%95%BF%E5%BA%A6%E6%83%A9%E7%BD%9A%EF%BC%89/</url>
    
    <content type="html"><![CDATA[<table><thead><tr><th><strong>题目</strong></th><th>The Implicit Length Bias of Label Smoothing on Beam Search Decoding</th></tr></thead><tbody><tr><td><strong>论文链接</strong></td><td><a href="https://arxiv.org/pdf/2205.00659.pdf">https://arxiv.org/pdf/2205.00659.pdf</a></td></tr><tr><td><strong>作者列表</strong></td><td>Bowen Liang, Pidong Wang, Yuan Cao</td></tr><tr><td><strong>作者单位</strong></td><td>Google</td></tr><tr><td><strong>文章类型</strong></td><td>短文</td></tr><tr><td><strong>撰写人</strong></td><td>C.Y.</td></tr></tbody></table><h2 id="核心任务和思想"><a href="#核心任务和思想" class="headerlink" title="核心任务和思想"></a>核心任务和思想</h2><p>通过数学推导在理论上说明训练时采用标签平滑会隐式地导致beam search解码机器翻译任务时存在长度惩罚，使得解码倾向于给出较短的结果，且理论上，标签平滑的模型会使得解码的长度存在与输入无关的常数上界。作者在实验中也发现了上述现象，并提出了修正方法。</p><h2 id="背景知识"><a href="#背景知识" class="headerlink" title="背景知识"></a>背景知识</h2><p>标签平滑是一种正则化防止过拟合的方法，它将独热的标签平滑为实数向量，计算方法如下：</p><p><img src="https://i1lqvqtgqs.feishu.cn/space/api/box/stream/download/asynccode/?code=ZjIzODc4ZjZjNzJmMTZmOTFmOWM5MmZhN2ZiMzA5ZWRfV2dEU1pQcGNGdWxVNXNjZk8yNVhYMmlNalVxcHdaMHBfVG9rZW46Ym94Y25sTktMRlFkSjdtV2tiaVBaOWlMUGtnXzE2NjEzNDg5NTQ6MTY2MTM1MjU1NF9WNA" alt="img"></p><p>其中q是平滑前的概率向量（向量的维度为词表大小V，向量中每个元素代表对应索引的词的概率），它是独热的。α是超参数，一般取为0.1。平滑后，原来为1的元素会略微减小，原来为0的元素会略微增大。</p><p>我们设模型给出的最后一层输出为向量q<code>，在充分训练后，q</code>可以视为模型给出的下一个时间步每个单词的概率，即有：</p><p><img src="https://i1lqvqtgqs.feishu.cn/space/api/box/stream/download/asynccode/?code=NmQ3ZjI1OWYyMjRkNDQzNDMyYTI0M2IxYWJlMzQyNzJfTHFYNDVBNDhmV1cxYTk4cXRRNkdMSXJUbkp5MzhlODNfVG9rZW46Ym94Y25QRXA2VVlIV2pXWVA0SlF5OHQ3cm1jXzE2NjEzNDg5NTQ6MTY2MTM1MjU1NF9WNA" alt="img"></p><p>在beam search解码时，我们的目标是得到一个对数概率尽量大的序列，但由上文可知，我们使用的p_hat和真正的概率q存在一定偏差，因此有下式：</p><p><img src="https://i1lqvqtgqs.feishu.cn/space/api/box/stream/download/asynccode/?code=M2M0ZDBhZjViMTZmZGNiY2I2OGI1ODk4NjEyZTdhYWNfeEh3M0h1a3JJWFdrSnVrRzRsRXB5U1JxZmFyWndZYkxfVG9rZW46Ym94Y25TUHFDWW53VVk3emtxNkJhREFON1dpXzE2NjEzNDg5NTQ6MTY2MTM1MjU1NF9WNA" alt="img"></p><p>其中T是序列长度，y_t是t时间步的输出（序列的第t个词），可以看到最后序列的对数概率与真实的对数概率存在与序列长度线性相关的偏差，而log(1-α)是一个负值，当α取0.1时为-0.105，导致T越小，序列越短，对数概率越大，因此解码倾向于给出越短的序列。</p><p>继续计算，我们可以得到p_hat的上下界：</p><p><img src="https://i1lqvqtgqs.feishu.cn/space/api/box/stream/download/asynccode/?code=YjdiN2Q5M2M2ZjJkMzhjNGVmMDllMDdiYTJhNTY1NWZfNkxIaU5PWTJmOUU4eWhIVzVpRDRXcTJlNWdsdEdDaGRfVG9rZW46Ym94Y241UTVoSW82RVBraDBXZnFBZWRPZWdkXzE2NjEzNDg5NTQ6MTY2MTM1MjU1NF9WNA" alt="img"></p><p>那么对于空序列（仅由EOS构成）和某个序列，有：</p><p><img src="https://i1lqvqtgqs.feishu.cn/space/api/box/stream/download/asynccode/?code=ZjMzNjRiMTkwMmY2ZDc1NGI3ZmY4MWU4MmZmODlmNTNfTVJqUTVDRjRlRWZMWUNFWGozTTFJUTVTMDhOc1g5Z1VfVG9rZW46Ym94Y25MNlk4ZmVITmxDa3lEWjdFZFEwUmJqXzE2NjEzNDg5NTQ6MTY2MTM1MjU1NF9WNA" alt="img"></p><p>两式比较，可以得到T有如此上界：</p><p><img src="https://i1lqvqtgqs.feishu.cn/space/api/box/stream/download/asynccode/?code=NWQxNWJiZjZkYjYxYTc3YzM4ZjM4ZDM2MjQ5YjVjMTdfdnJDSkxxcHI5b3VRMnFaWW9rMTFaNnhmbjhNZHA0SXFfVG9rZW46Ym94Y245eDdqMFlGNDQxdElSMkQweEN4RGllXzE2NjEzNDg5NTQ6MTY2MTM1MjU1NF9WNA" alt="img"></p><h2 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h2><p>通过上述的理论推导，将第一个公式逆过来，得到修正公式：</p><p><img src="https://i1lqvqtgqs.feishu.cn/space/api/box/stream/download/asynccode/?code=ZWUwMGJmNDk4YmM0MzlkMDliMzY4N2ExOTM3Yjc2MjZfN2Y4RmoyN2VRTUZtTDNEUkJ6RnN3WlFCNDNIOWIzdUxfVG9rZW46Ym94Y25UTHpMSEhsRWdGRERSODZpNE1PSkliXzE2NjEzNDg5NTQ6MTY2MTM1MjU1NF9WNA" alt="img"></p><p>由于模型训练的结果不完全是概率，这样计算后概率值可能会超出[0, 1]，因此作者又增加了ReLU来避免这种情况。</p><p>加上归一化，最终结果如下：</p><p><img src="https://i1lqvqtgqs.feishu.cn/space/api/box/stream/download/asynccode/?code=OGNjYjQ2MWIzNTY1YjI1YzE2ZmRkOTVjY2VkMDMxYjBfcHpzMzZrZzVyWGVtb1BtSXRjUm5odFdXSE9sRGw3RFBfVG9rZW46Ym94Y25pRzJURGRETjQ2czNHbTBXZjJwQ1J6XzE2NjEzNDg5NTQ6MTY2MTM1MjU1NF9WNA" alt="img"></p><p>其中δ&#x3D;α &#x2F; V 。</p><p>作者使用修正后的概率值，使用beam search进行实验。</p><p>作者将模型的 δ 设为  n &#x2F; V，其中n &#x3D; 0.1、1、100，同时也探究了beam size分别为1、4、8、25、100、200的结果。</p><h2 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h2><ul><li><h3 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h3></li><li><p>WMT19 EnDe, EnCs, EnZh 和 WMT15 EnFr. </p></li><li><h3 id="评测指标"><a href="#评测指标" class="headerlink" title="评测指标"></a>评测指标</h3></li><li><p>BLEU值</p></li><li><p>翻译长度 &#x2F; 源句子长度</p></li><li><h3 id="基线方法"><a href="#基线方法" class="headerlink" title="基线方法"></a>基线方法</h3></li><li><p>基于Transformer训练的机器翻译模型，没有标签平滑。</p></li><li><p>基于Transformer训练的机器翻译模型，采用α &#x3D; 0.1的标签平滑，但在解码时不采用上述偏差修正，即δ &#x3D; 0。</p></li><li><h3 id="主实验结果及分析"><a href="#主实验结果及分析" class="headerlink" title="主实验结果及分析"></a>主实验结果及分析</h3></li><li><p>所有模型解码时不采用长度惩罚（因为这会使上述推导的T项被除去）</p></li><li><p>结果1：</p><ul><li>在EnDe数据集上BLEU值与δ、beam size的关系如下：</li></ul></li></ul><p><img src="https://i1lqvqtgqs.feishu.cn/space/api/box/stream/download/asynccode/?code=MzI3NzhiMjVjOGI3M2JkM2U3ZWZmOTU2NjZjMzE1ODVfaGpoQ3dkSU5KdVRhMjBWUjQ4cDJkMU1yZ2NnSlRyMlJfVG9rZW46Ym94Y25aV1pVN1VISnBwSE1KbGFDTlU3SDZiXzE2NjEzNDg5NTQ6MTY2MTM1MjU1NF9WNA" alt="img"></p><ul><li><p>可以看到修正对贪心搜索没有影响，而随着k增大，修正的影响更大，在beam size &#x3D; 200时，修正在横轴范围内使得BLEU值持续增大。</p></li><li><p>结果2：</p><ul><li>在EnDe数据集上，当beam size &#x3D; 200时，BLEU值与源句子长度，是否标签平滑、修正程度的关系如下：</li></ul></li></ul><p><img src="https://i1lqvqtgqs.feishu.cn/space/api/box/stream/download/asynccode/?code=MTA3MjE0ZDcyMDYwZjU0ZTg0ZThkYWE5YTdiZjUyZDFfamJvQlZQSXh1bkY3Tm5KUHZxYk9xc3U1QTJMc1RJZG5fVG9rZW46Ym94Y25sWGFOTHFzMzl1cmFGWU15cDhiVUdlXzE2NjEzNDg5NTQ6MTY2MTM1MjU1NF9WNA" alt="img"></p><ul><li><p>可以看到没有标签平滑的模型在较长查询中性能优于标签平滑模型。而修正后也能让较长查询的结果更好。</p></li><li><p>结果3：</p><ul><li>在EnDe数据集上，长度比值和源句子长度、δ的关系如下：</li></ul></li></ul><p><img src="https://i1lqvqtgqs.feishu.cn/space/api/box/stream/download/asynccode/?code=NWQ0NDZkYjJiNzRhZjUzNDVkNmVjNTlkMmEyYzIyNWFfcDhnYllCQ0dsRGVwcTR3d0tUM1JmQVdXV3QyZGZxQk5fVG9rZW46Ym94Y25kVTFJWjc4aHp6UXI3dmcxaWtXUXFnXzE2NjEzNDg5NTQ6MTY2MTM1MjU1NF9WNA" alt="img"></p><ul><li><p>可以看到没有标签平滑、修正后的标签平滑均有利于生成更长的句子，且有利于更长的查询。</p></li><li><p>结果4：</p><ul><li>不同数据集上的结果（BLEU值）：</li></ul></li></ul><p><img src="https://i1lqvqtgqs.feishu.cn/space/api/box/stream/download/asynccode/?code=NTZiMWIzZGFhZTA2YzQzOTkzNjdlNmI0YjkyNTY5MjRfY1ZyN0tuSTc1VGdkV3ptV2xLZkhwZ01zdzdiN2daY0JfVG9rZW46Ym94Y25GanoyWGg1T3hNRlNQVkZxd2lRYXNmXzE2NjEzNDg5NTQ6MTY2MTM1MjU1NF9WNA" alt="img"></p><ul><li><p>可以看到beam size为4时，δ &#x3D; 1 &#x2F; V是一个峰值，beam size为200时，随δ上升模型性能都有上升。这与预期相符。</p></li><li><h3 id="副实验设置、结果、分析"><a href="#副实验设置、结果、分析" class="headerlink" title="副实验设置、结果、分析"></a>副实验设置、结果、分析</h3></li><li><p>副实验主要探究修正后是否会让模型过度自信（因为设置标签平滑就是为了防止过拟合）。</p></li><li><p>数据集和模型：仍采用上述数据集和模型</p></li><li><p>评测指标：Set-Level Calibration analysis。对于每个查询，将前 200 个beam搜索输出的预测概率相加，用 S 表示，并将参考句子包含在S中的实际频率进行比较，模型校准越好，两个数字越匹配。</p></li><li><p>结果如下：</p></li></ul><p><img src="https://i1lqvqtgqs.feishu.cn/space/api/box/stream/download/asynccode/?code=NGJhNDQyOWMxODY2MDkxNTIxZjQxYWQzNzVmMzRjZGNfYnEwZXFMMERYWUlrYm00bnM4YXI0M0xSek1YRWNVaTNfVG9rZW46Ym94Y25aN1dBVDZVYmdxNGV3Y2ZMWkw4WUFjXzE2NjEzNDg5NTQ6MTY2MTM1MjU1NF9WNA" alt="img"></p><p>标签平滑且无修正的系统过于自信，而经过修正后可以非常匹配。</p><h2 id="个人点评和启发"><a href="#个人点评和启发" class="headerlink" title="个人点评和启发"></a>个人点评和启发</h2><p>用理论推导出beam search解码中存在的问题，并通过实验验证。</p><p>我认为最后合适的δ取1 &#x2F; V暗示着模型在其他地方还有系统误差（如果只是标签平滑带来的误差，那应该在0.1 &#x2F; V左右达到最佳）。</p><p>如果是我来修正，根据理论用[0, 1]外的值截断更合理。因为ReLU解决了修正后小于0的概率修正为0的问题，但不会把修正后超过1的概率截断为1，用ReLU后的结果归一化就让人感觉怪怪的。不过由于修正后概率超过1的其实很少（至多有1个，至少有0个），所以应该不会特别影响实验结果。</p>]]></content>
    
    
    <categories>
      
      <category>论文笔记</category>
      
      <category>解码方法</category>
      
    </categories>
    
    
    <tags>
      
      <tag>NLP</tag>
      
      <tag>解码方法</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>文章格式模板</title>
    <link href="/2022/08/24/%E6%96%87%E7%AB%A0%E6%A0%BC%E5%BC%8F%E8%AE%B0%E5%BD%95/"/>
    <url>/2022/08/24/%E6%96%87%E7%AB%A0%E6%A0%BC%E5%BC%8F%E8%AE%B0%E5%BD%95/</url>
    
    <content type="html"><![CDATA[<h1 id="模板"><a href="#模板" class="headerlink" title="模板"></a>模板</h1><h2 id="Front-Matter"><a href="#Front-Matter" class="headerlink" title="Front-Matter"></a>Front-Matter</h2><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs markdown">---<br><span class="hljs-section">#冒号后都要加空格！</span><br>title: 文章标题<br>tags: [Hexo, Fluid]  #标签<br>index<span class="hljs-emphasis">_img: /img/example.jpg   #首页展示的文章图</span><br><span class="hljs-emphasis">banner_</span>img: /img/post<span class="hljs-emphasis">_banner.jpg #文章上部大图</span><br><span class="hljs-emphasis">date: 2019-10-10 10:00:00 #优先根据 front-matter 里 date 字段，其次是 md 文件日期</span><br><span class="hljs-emphasis">updated: 2019-10-10 10:00:01 #指定更新时间</span><br><span class="hljs-emphasis">excerpt: 摘要</span><br><span class="hljs-emphasis"></span><br><span class="hljs-emphasis">categories:</span><br><span class="hljs-emphasis">- [Diary, PlayStation]</span><br><span class="hljs-emphasis">- [Diary, Games]</span><br><span class="hljs-emphasis">- [Life]</span><br><span class="hljs-emphasis"></span><br><span class="hljs-emphasis">hide: true #在首页隐藏，且会使文章在分类和标签类里都不显示</span><br><span class="hljs-emphasis">sticky: 100 #数值越大，该文章越靠前，达到类似于置顶的效果</span><br><span class="hljs-emphasis"></span><br><span class="hljs-emphasis">---</span><br><span class="hljs-emphasis">以下是文章内容</span><br></code></pre></td></tr></table></figure><p>手动指定摘要的另一种方式，使用 <code>&lt;!-- more --&gt;</code> MD文档里划分，如：</p><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs markdown">正文的一部分作为摘要<br>&lt;!-- more --&gt;<br>余下的正文<br></code></pre></td></tr></table></figure><h2 id="正文"><a href="#正文" class="headerlink" title="正文"></a>正文</h2><h3 id="脚注"><a href="#脚注" class="headerlink" title="脚注"></a>脚注</h3><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs markdown">这是一句话 [^1]<br>[<span class="hljs-symbol">^1</span>]: <span class="hljs-link">这是对应的脚注</span><br></code></pre></td></tr></table></figure><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs markdown">正文<br><br><span class="hljs-section">## 参考</span><br>[<span class="hljs-symbol">^1</span>]: <span class="hljs-link">参考资料1</span><br>[<span class="hljs-symbol">^2</span>]: <span class="hljs-link">参考资料2</span><br></code></pre></td></tr></table></figure><h3 id="勾选框"><a href="#勾选框" class="headerlink" title="勾选框"></a>勾选框</h3><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs markdown">&#123;% cb text, checked?, incline? %&#125;<br></code></pre></td></tr></table></figure><p>依次是文本、是否勾选、后面的文字是否不换行（默认false换行）</p><h3 id="按钮"><a href="#按钮" class="headerlink" title="按钮"></a>按钮</h3><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs markdown">&#123;% btn url, text, title %&#125;<br></code></pre></td></tr></table></figure><p>依次是跳转链接、按钮文本、鼠标悬停文本</p><h3 id="组图"><a href="#组图" class="headerlink" title="组图"></a>组图</h3><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs markdown">&#123;% gi total n1-n2-... %&#125;<br>  ![](<span class="hljs-link">url</span>)<br>  ![](<span class="hljs-link">url</span>)<br>  ![](<span class="hljs-link">url</span>)<br>  ![](<span class="hljs-link">url</span>)<br>  ![](<span class="hljs-link">url</span>)<br>&#123;% endgi %&#125;<br></code></pre></td></tr></table></figure><p>total：图片总数量，对应中间包含的图片 url 数量。<br>n1-n2-…：每行的图片数量，可以省略，默认单行最多 3 张图，求和必须相等于 total，否则按默认样式。</p><h3 id="便签"><a href="#便签" class="headerlink" title="便签"></a>便签</h3><h4 id="行便签"><a href="#行便签" class="headerlink" title="行便签"></a>行便签</h4><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs markdown">&#123;% note success %&#125;<br>文字 或者 <span class="hljs-code">`markdown`</span> 均可<br>&#123;% endnote %&#125;<br></code></pre></td></tr></table></figure><div class="note note-primary">            <p>primary</p>          </div><div class="note note-secondary">            <p>secondary</p>          </div><div class="note note-success">            <p>success</p>          </div><div class="note note-info">            <p>info</p>          </div><div class="note note-danger">            <p>danger</p>          </div><div class="note note-warning">            <p>warning</p>          </div><div class="note note-light">            <p>light</p>          </div><h4 id="行内便签"><a href="#行内便签" class="headerlink" title="行内便签"></a>行内便签</h4><p>注意text不能以@开头。也就是不能@后还接一个@。</p><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs markdown">&#123;% label primary @text %&#125;<br></code></pre></td></tr></table></figure><span class="label label-primary">primary</span> <span class="label label-default">default</span> <span class="label label-info">info</span> <span class="label label-success">success</span> <span class="label label-warning">warning</span> <span class="label label-danger">danger</span>]]></content>
    
    
    <categories>
      
      <category>Hexo相关</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Hexo</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Hello World</title>
    <link href="/2022/08/23/hello-world/"/>
    <url>/2022/08/23/hello-world/</url>
    
    <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo new <span class="hljs-string">&quot;My New Post&quot;</span><br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo server<br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo generate<br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo deploy<br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>]]></content>
    
    
    
    <tags>
      
      <tag>Genesis</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
